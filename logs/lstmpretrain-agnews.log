W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Initialized RandomSearch of size 2 / 1
================================================================================
[1] Testing l2_penalty = 0.1, lr = 0.01, loss_function = log, n_epochs = 50
================================================================================
[LSTMPreTrain] dim=300 lr=0.01 l2=0.1 ngram=2
[LSTMPreTrain] Building model
/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
[LSTMPreTrain] Training model
[LSTMPreTrain] #examples=5000  #epochs=50  batch size=256
[LSTMPreTrain] Found dev set for training eval
[LSTMPreTrain] Epoch 1 (550.41s)	Avg. loss = 0.864525	Dev acc. = 46.40%
[LSTMPreTrain] Epoch 5 (3029.54s)	Avg. loss = 0.219272	Dev acc. = 95.30%
[LSTMPreTrain] Epoch 10 (6777.18s)	Avg. loss = 0.232700	Dev acc. = 94.40%
[LSTMPreTrain] Epoch 15 (9038.09s)	Avg. loss = 0.005011	Dev acc. = 95.20%
[LSTMPreTrain] Epoch 20 (11074.93s)	Avg. loss = 0.003115	Dev acc. = 95.40%
[LSTMPreTrain] Epoch 25 (13504.97s)	Avg. loss = 0.002672	Dev acc. = 95.40%
[LSTMPreTrain] Epoch 30 (15506.37s)	Avg. loss = 0.002483	Dev acc. = 95.40%
[LSTMPreTrain] Epoch 35 (17077.82s)	Avg. loss = 0.002364	Dev acc. = 95.40%
[LSTMPreTrain] Epoch 40 (18375.26s)	Avg. loss = 0.002277	Dev acc. = 95.50%
[LSTMPreTrain] Epoch 45 (19695.23s)	Avg. loss = 0.002215	Dev acc. = 95.30%
[LSTMPreTrain] Epoch 50 (20744.77s)	Avg. loss = 0.002132	Dev acc. = 95.30%
[LSTMPreTrain] Training done (20744.77s)
[LSTMPreTrain] Test set unknown token percentage: 5.17%
[LSTMPreTrain] Accuracy: 95.30%
================================================================================
[2] Testing l2_penalty = 0.001, lr = 0.01, loss_function = log, n_epochs = 50
================================================================================
[LSTMPreTrain] dim=300 lr=0.01 l2=0.001 ngram=2
[LSTMPreTrain] Building model
Traceback (most recent call last):
  File "fit_model.py", line 96, in <module>
    run(model, config, args.embedding, args.word_freq, args.n_threads)
  File "fit_model.py", line 72, in run
    df = S.fit(dev_X, dev_y, b=b, **fixed_parameters)
  File "/lfs/raiders7/hdd/daniter/nlp-proj/shalo/shalo/model_search.py", line 101, in fit
    **model_hyperparams
  File "/lfs/raiders7/hdd/daniter/nlp-proj/shalo/shalo/shalo_base.py", line 157, in train
    self._build()
  File "/lfs/raiders7/hdd/daniter/nlp-proj/shalo/shalo/shalo_base.py", line 80, in _build
    sentence_feats, save_kwargs = self._embed_sentences()
  File "/lfs/raiders7/hdd/daniter/nlp-proj/shalo/shalo/baseline.py", line 123, in _embed_sentences
    initial_state=initial_state, time_major=False               
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py", line 546, in dynamic_rnn
    dtype=dtype)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py", line 713, in _dynamic_rnn_loop
    swap_memory=swap_memory)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py", line 2605, in while_loop
    result = context.BuildLoop(cond, body, loop_vars, shape_invariants)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py", line 2438, in BuildLoop
    pred, body, original_loop_vars, loop_vars, shape_invariants)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py", line 2388, in _BuildLoop
    body_result = body(*packed_vars_for_body)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py", line 696, in _time_step
    skip_conditionals=True)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py", line 177, in _rnn_step
    new_output, new_state = call_cell()
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py", line 684, in <lambda>
    call_cell = lambda: cell(input_t, state)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py", line 179, in __call__
    concat = _linear([inputs, h], 4 * self._num_units, True, scope=scope)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py", line 747, in _linear
    "weights", [total_arg_size, output_size], dtype=dtype)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py", line 988, in get_variable
    custom_getter=custom_getter)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py", line 890, in get_variable
    custom_getter=custom_getter)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py", line 348, in get_variable
    validate_shape=validate_shape)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py", line 333, in _true_getter
    caching_device=caching_device, validate_shape=validate_shape)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py", line 639, in _get_single_variable
    name, "".join(traceback.format_list(tb))))
ValueError: Variable LSTM/rnn/basic_lstm_cell/weights already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:

  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py", line 747, in _linear
    "weights", [total_arg_size, output_size], dtype=dtype)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py", line 179, in __call__
    concat = _linear([inputs, h], 4 * self._num_units, True, scope=scope)
  File "/lfs/raiders7/hdd/daniter/nlp-proj/shalo/shalo/baseline.py", line 123, in _embed_sentences
    initial_state=initial_state, time_major=False

